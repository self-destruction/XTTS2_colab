{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# –¢–µ–∫—Å—Ç –≤ —Ä–µ—á—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
        "[![–û—Ç–∫—Ä—ã—Ç—å –≤ Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/self-destruction/XTTS2_colab/blob/main/XTTS_v2_RU.ipynb)\n",
        "#### –î–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å –Ω–µ–æ–±—Ö–æ–¥–∏–º –Ω–µ–±–æ–ª—å—à–æ–π –æ—Ç—Ä—ã–≤–æ–∫ —á–∏—Å—Ç–æ–π —Ä–µ—á–∏ –ø–∞—Ä–æ–¥–∏—Ä—É–µ–º–æ–≥–æ. –î–∞–ª–µ–µ —Ñ–∞–π–ª –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞–µ—Ç—Å—è –æ—Ç –ø–∞—É–∑ –∏ —à—É–º–∞. –ò –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å."
      ],
      "metadata": {
        "id": "1zeuHPLu2UPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π TTS\n",
        "%cd /content\n",
        "!git clone https://github.com/coqui-ai/TTS.git -b dev\n",
        "!mkdir /content/input\n",
        "!mkdir /content/output\n",
        "\n",
        "XTTS_V2_DIR = '/content/XTTS-v2'\n",
        "!mkdir {XTTS_V2_DIR}\n",
        "!wget https://huggingface.co/coqui/XTTS-v2/resolve/main/model.pth -P {XTTS_V2_DIR} &> /dev/null\n",
        "!wget https://huggingface.co/coqui/XTTS-v2/resolve/main/config.json -P {XTTS_V2_DIR} &> /dev/null\n",
        "\n",
        "TTS_DIR = '/content/TTS'\n",
        "%cd {TTS_DIR}\n",
        "!apt install -q ffmpeg\n",
        "!pip install virtualenv\n",
        "!virtualenv venv\n",
        "!source {TTS_DIR}/venv/bin/activate; pip3 install -q llvmlite --ignore-installed\n",
        "!source {TTS_DIR}/venv/bin/activate; pip3 install -q torch torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
        "!source {TTS_DIR}/venv/bin/activate; pip install -q -r requirements.txt\n",
        "# –∫–æ—Å—Ç—ã–ª–∏\n",
        "!sed -i 's/ # Not sure what sets this to None, but applied a fix to prevent crashing./ return True/g' {TTS_DIR}/TTS/api.py\n",
        "!sed -i 's/text=sen,/text=sen.rstrip(\\'.\\'),/g' {TTS_DIR}/TTS/utils/synthesizer.py"
      ],
      "metadata": {
        "id": "zijDl1Hl3wOx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "from IPython.display import Audio\n",
        "\n",
        "#@title –ó–∞–≥—Ä—É–∑–∫–∞ mp3-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞\n",
        "file_folder = '/content/input' #@param {type:\"string\"}\n",
        "!mkdir -p {file_folder}\n",
        "%cd {file_folder}\n",
        "INPUT_FILE = ''\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for file_name in uploaded.keys():\n",
        "  INPUT_FILE = os.path.join(file_folder, file_name)\n",
        "\n",
        "print(f\"\\n–ü—Ä–æ–≤–µ—Ä—å, –≤—Å—ë –ª–∏ –æ–∫ üëá\")\n",
        "audio = Audio(INPUT_FILE, autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "M3RIpDORodCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "from IPython.display import Audio\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "#@title –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∞—É–¥–∏–æ\n",
        "# @markdown ### –ö–æ–ª-–≤–æ —Å–µ–∫—É–Ω–¥, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –≤–æ–∑—å–º—ë–º –≤ —á–∏—Å—Ç—ã–π —Ñ–∞–π–ª:\n",
        "TIME_SEC=3 # @param {type:\"slider\", min:1, max:20, step:1}\n",
        "# @markdown ---\n",
        "# @markdown ### –°–¥–≤–∏–≥ –Ω–∞—á–∞–ª–∞:\n",
        "# @markdown ##### (–Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –Ω–µ –ø–æ–≤–µ–∑–ª–æ —Å –Ω–∞—á–∞–ª–æ–º)\n",
        "TIME_OFFSET=1 # @param {type:\"slider\", min:0, max:20, step:1}\n",
        "# @markdown ---\n",
        "# @markdown ### –ü–æ—Ä–æ–≥ —à—É–º–∞ –≤ dB (-25dB - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, -80dB –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –∏—Å—Ö–æ–¥–Ω–∏–∫–∞, -20dB –¥–ª—è –û–ß–ï–ù–¨ –≥—Ä—è–∑–Ω–æ–≥–æ):\n",
        "NOISE_THRESHOLD=-25   # @param {type:\"slider\", min:-120, max:-1, step:1}\n",
        "\n",
        "INPUT_CLEAN_FILE = '/content/input/input_audio_clean.mp3'\n",
        "\n",
        "TIME_SEC=str(TIME_SEC+TIME_OFFSET) # —Ö–∞–∫ –ø—Ä–∏ –Ω–µ–Ω—É–ª–µ–≤–æ–º —Å–¥–≤–∏–≥–µ\n",
        "NOISE_THRESHOLD=str(NOISE_THRESHOLD)\n",
        "TIME_OFFSET=str(TIME_OFFSET)\n",
        "\n",
        "!ffmpeg -y -hide_banner -loglevel error -i '{INPUT_FILE}' -af lowpass=8000,highpass=75,areverse,silenceremove=stop_periods=-1:stop_duration=1:stop_threshold={NOISE_THRESHOLD}dB:stop_silence=0:start_periods=9000:start_silence=0,areverse,silenceremove=stop_periods=-1:stop_duration=1:stop_threshold={NOISE_THRESHOLD}dB:stop_silence=0:start_periods=9000:start_silence=0,atrim={TIME_OFFSET}:{TIME_SEC} {INPUT_CLEAN_FILE}\n",
        "print(f\"\\n–ü—Ä–æ–≤–µ—Ä—å, –≤—Å—ë –ª–∏ –æ–∫ üëá\")\n",
        "audio = Audio(INPUT_CLEAN_FILE, autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hJ94xj7W-1Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {TTS_DIR}\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "#@title # üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¢–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å\n",
        "# @markdown ### –¢–µ–∫—Å—Ç:\n",
        "PROMPT = \"\"  #@param {type:\"string\"}\n",
        "# @markdown ---\n",
        "# @markdown ### –ü—É—Ç—å –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É:\n",
        "OUTPUT_FILE = \"/content/output/speech.mp3\"  #@param {type:\"string\"}\n",
        "\n",
        "from IPython.display import Audio, display, HTML, FileLink;\n",
        "\n",
        "cmd = (\n",
        "    f\"import torch; from TTS.api import TTS; \"\n",
        "    f\"device = 'cuda' if torch.cuda.is_available() else 'cpu'; \"\n",
        "    f\"tts = TTS(model_path='/content/XTTS-v2', config_path='/content/XTTS-v2/config.json', progress_bar=False).to(device); \"\n",
        "    f\"tts.tts_to_file(text='{PROMPT}', speaker_wav='{INPUT_CLEAN_FILE}', language='ru', file_path='{OUTPUT_FILE}'); \"\n",
        ")\n",
        "\n",
        "!source {TTS_DIR}/venv/bin/activate; python -c \"{cmd}\"\n",
        "\n",
        "audio = Audio(OUTPUT_FILE, autoplay=False)\n",
        "display(audio)"
      ],
      "metadata": {
        "id": "GMiOfS_0d70f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}